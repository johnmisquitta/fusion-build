<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Microphone Specifications Test</title>
</head>
<body>
  <h1>Microphone Specifications Test</h1>
  <button onclick="startAudio()">Start Microphone Access</button>
  <div id="output"></div>

  <script>
    async function startAudio() {
      try {
        // Request access to the microphone with specific constraints
        const constraints = {
          audio: {
            sampleRate: 48000,        // Request a sample rate of 44100 Hz (if available)
            channelCount: 1,          // Request stereo audio (2 channels) if available
            echoCancellation: true    // Enable echo cancellation if available
          }
        };
        
        // Request audio stream
        const stream = await navigator.mediaDevices.getUserMedia(constraints);
        
        // Display MediaTrack constraints (actual configuration used by the browser)
        const audioTracks = stream.getAudioTracks();
        const trackSettings = audioTracks[0].getSettings();
        document.getElementById("output").innerHTML = `
          <p><strong>Sample Rate:</strong> ${trackSettings.sampleRate || 'Not specified'}</p>
          <p><strong>Channel Count:</strong> ${trackSettings.channelCount || 'Not specified'}</p>
          <p><strong>Echo Cancellation:</strong> ${trackSettings.echoCancellation || 'Not specified'}</p>
          <p><strong>Device ID:</strong> ${audioTracks[0].getSettings().deviceId || 'Not accessible'}</p>
        `;

        // Enumerate devices to identify microphone info
        const devices = await navigator.mediaDevices.enumerateDevices();
        const microphoneDevices = devices.filter(device => device.kind === 'audioinput');
        microphoneDevices.forEach((device, index) => {
          document.getElementById("output").innerHTML += `
            <p><strong>Microphone ${index + 1}:</strong> ${device.label || 'Label not available'} (ID: ${device.deviceId})</p>
          `;
        });

        // Create an audio context and get the sample rate
        const audioContext = new (window.AudioContext || window.webkitAudioContext)();
        const sampleRate = audioContext.sampleRate;
        document.getElementById("output").innerHTML += `<p><strong>Audio Context Sample Rate:</strong> ${sampleRate} Hz</p>`;

        // Connect audio source and setup analyser
        const source = audioContext.createMediaStreamSource(stream);
        const analyser = audioContext.createAnalyser();
        source.connect(analyser);

        // Configure AnalyserNode properties
        analyser.fftSize = 2048;
        const bufferLength = analyser.frequencyBinCount;
        const dataArray = new Float32Array(bufferLength);
        
        // Display real-time frequency data (console logging for demo purposes)
        function analyzeAudio() {
          analyser.getFloatFrequencyData(dataArray);
          console.log("Frequency Data:", dataArray); // This outputs frequency data for analysis
        }
        
        // Call analyzeAudio at intervals
        setInterval(analyzeAudio, 1000);

      } catch (error) {
        console.error("Error accessing microphone:", error);
        document.getElementById("output").innerText = "Microphone access denied or not supported.";
      }
    }
  </script>
</body>
</html>
